{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6004344,"sourceType":"datasetVersion","datasetId":3438844}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Tools","metadata":{}},{"cell_type":"code","source":"from transformers import T5ForConditionalGeneration, T5Tokenizer, Trainer, TrainingArguments\nimport pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T05:30:19.396931Z","iopub.execute_input":"2024-12-19T05:30:19.397296Z","iopub.status.idle":"2024-12-19T05:30:37.305453Z","shell.execute_reply.started":"2024-12-19T05:30:19.397251Z","shell.execute_reply":"2024-12-19T05:30:37.304510Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# Load Datasets","metadata":{}},{"cell_type":"code","source":"# Load dataset (example, adjust path as needed)\ntrain_data = pd.read_csv(\"/kaggle/input/samsum-dataset-text-summarization/samsum-train.csv\")\nvalidation_data = pd.read_csv(\"/kaggle/input/samsum-dataset-text-summarization/samsum-test.csv\")\n\n# Display a sample (by default shows 5 top lines)\ntrain_data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T05:30:37.307036Z","iopub.execute_input":"2024-12-19T05:30:37.307601Z","iopub.status.idle":"2024-12-19T05:30:37.623005Z","shell.execute_reply.started":"2024-12-19T05:30:37.307572Z","shell.execute_reply":"2024-12-19T05:30:37.622079Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"         id                                           dialogue  \\\n0  13818513  Amanda: I baked  cookies. Do you want some?\\r\\...   \n1  13728867  Olivia: Who are you voting for in this electio...   \n2  13681000  Tim: Hi, what's up?\\r\\nKim: Bad mood tbh, I wa...   \n3  13730747  Edward: Rachel, I think I'm in ove with Bella....   \n4  13728094  Sam: hey  overheard rick say something\\r\\nSam:...   \n\n                                             summary  \n0  Amanda baked cookies and will bring Jerry some...  \n1  Olivia and Olivier are voting for liberals in ...  \n2  Kim may try the pomodoro technique recommended...  \n3  Edward thinks he is in love with Bella. Rachel...  \n4  Sam is confused, because he overheard Rick com...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>dialogue</th>\n      <th>summary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>13818513</td>\n      <td>Amanda: I baked  cookies. Do you want some?\\r\\...</td>\n      <td>Amanda baked cookies and will bring Jerry some...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>13728867</td>\n      <td>Olivia: Who are you voting for in this electio...</td>\n      <td>Olivia and Olivier are voting for liberals in ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>13681000</td>\n      <td>Tim: Hi, what's up?\\r\\nKim: Bad mood tbh, I wa...</td>\n      <td>Kim may try the pomodoro technique recommended...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>13730747</td>\n      <td>Edward: Rachel, I think I'm in ove with Bella....</td>\n      <td>Edward thinks he is in love with Bella. Rachel...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>13728094</td>\n      <td>Sam: hey  overheard rick say something\\r\\nSam:...</td>\n      <td>Sam is confused, because he overheard Rick com...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"train_data = train_data.sample(n=4000, random_state=42).reset_index(drop=True)\nvalidation_data = validation_data.sample(n=500, random_state=42).reset_index(drop=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T05:30:37.624304Z","iopub.execute_input":"2024-12-19T05:30:37.624697Z","iopub.status.idle":"2024-12-19T05:30:37.636512Z","shell.execute_reply.started":"2024-12-19T05:30:37.624654Z","shell.execute_reply":"2024-12-19T05:30:37.635574Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"code","source":"# Clean the text by removing unwanted characters\nimport re\n\ndef clean_text(text):\n    text = re.sub(r'\\r\\n', ' ', text) # remove carriage returns and line breaks \n    text = re.sub(r'\\s+', ' ', text) # remove extra spaces\n    text = re.sub(r'<.*?>', '', text) # remove any xml/html tags\n    text = text.strip().lower() # removes end spaces and covert to lower case\n    return text\n    # we do not remove stop words because we have to summarize the text\n\n# Apply cleaning to dialogue and summary columns\ntrain_data['dialogue'] = train_data['dialogue'].apply(clean_text)\ntrain_data['summary'] = train_data['summary'].apply(clean_text)\n\nvalidation_data['dialogue'] = validation_data['dialogue'].apply(clean_text)\nvalidation_data['summary'] = validation_data['summary'].apply(clean_text)\n\n# Display a sample after cleaning\ntrain_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T05:30:37.639111Z","iopub.execute_input":"2024-12-19T05:30:37.639664Z","iopub.status.idle":"2024-12-19T05:30:37.853515Z","shell.execute_reply.started":"2024-12-19T05:30:37.639635Z","shell.execute_reply":"2024-12-19T05:30:37.852627Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"            id                                           dialogue  \\\n0     13811908  violet: hi! i came across this austin's articl...   \n1     13716431  pat: so does anyone know when the stream is go...   \n2     13810214  jane:  jane: whaddya think? shona: this ur tin...   \n3     13729823  adam: do u have a map of paris? tom: yes, why?...   \n4     13681400  frank: hi, how's the family? mike: great! sam'...   \n...        ...                                                ...   \n3995  13681041  barry: hello buddy michael: hey barry: do you ...   \n3996  13818705  karen: hey lisa. larissa and me have recently ...   \n3997  13821859  miles: hey, guys, i'm so sorry, but i missed t...   \n3998  13812716  emma: did you finish the book i gave you? liam...   \n3999  13717021  jenna: dudes, were we supposed to read the who...   \n\n                                                summary  \n0                  violet sent claire austin's article.  \n1     pat and lou are waiting for the stream but kev...  \n2     jane is updating her tinder profile tonight an...  \n3                               tom has a map of paris.  \n4     mike is happy, because sam's moved out. mike a...  \n...                                                 ...  \n3995  barry and michael will watch football instead ...  \n3996  karen and larissa moved to belgium and ask lis...  \n3997  miles has missed the bus, so he may be 15 minu...  \n3998  emma gave \"the first fifteen lives of harry au...  \n3999  jenna, hannah and denis should read 40 pages f...  \n\n[4000 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>dialogue</th>\n      <th>summary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>13811908</td>\n      <td>violet: hi! i came across this austin's articl...</td>\n      <td>violet sent claire austin's article.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>13716431</td>\n      <td>pat: so does anyone know when the stream is go...</td>\n      <td>pat and lou are waiting for the stream but kev...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>13810214</td>\n      <td>jane:  jane: whaddya think? shona: this ur tin...</td>\n      <td>jane is updating her tinder profile tonight an...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>13729823</td>\n      <td>adam: do u have a map of paris? tom: yes, why?...</td>\n      <td>tom has a map of paris.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>13681400</td>\n      <td>frank: hi, how's the family? mike: great! sam'...</td>\n      <td>mike is happy, because sam's moved out. mike a...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3995</th>\n      <td>13681041</td>\n      <td>barry: hello buddy michael: hey barry: do you ...</td>\n      <td>barry and michael will watch football instead ...</td>\n    </tr>\n    <tr>\n      <th>3996</th>\n      <td>13818705</td>\n      <td>karen: hey lisa. larissa and me have recently ...</td>\n      <td>karen and larissa moved to belgium and ask lis...</td>\n    </tr>\n    <tr>\n      <th>3997</th>\n      <td>13821859</td>\n      <td>miles: hey, guys, i'm so sorry, but i missed t...</td>\n      <td>miles has missed the bus, so he may be 15 minu...</td>\n    </tr>\n    <tr>\n      <th>3998</th>\n      <td>13812716</td>\n      <td>emma: did you finish the book i gave you? liam...</td>\n      <td>emma gave \"the first fifteen lives of harry au...</td>\n    </tr>\n    <tr>\n      <th>3999</th>\n      <td>13717021</td>\n      <td>jenna: dudes, were we supposed to read the who...</td>\n      <td>jenna, hannah and denis should read 40 pages f...</td>\n    </tr>\n  </tbody>\n</table>\n<p>4000 rows × 3 columns</p>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"# Tokenization","metadata":{}},{"cell_type":"code","source":"tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T05:30:37.854752Z","iopub.execute_input":"2024-12-19T05:30:37.855137Z","iopub.status.idle":"2024-12-19T05:30:40.491283Z","shell.execute_reply.started":"2024-12-19T05:30:37.855099Z","shell.execute_reply":"2024-12-19T05:30:40.490594Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3b633234355475c8e67854eeb0aa5b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b10d338820414ec2a6c878794e606040"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"246e1f2e0fba4240bcfb697e15bbcdfe"}},"metadata":{}},{"name":"stderr","text":"You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Preprocessing function for tokenization\ndef preprocess_function(examples):\n    inputs = tokenizer(examples[\"dialogue\"], padding=\"max_length\", truncation=True, max_length=512)\n    targets = tokenizer(examples[\"summary\"], padding=\"max_length\", truncation=True, max_length=150)\n    inputs[\"labels\"] = targets[\"input_ids\"]\n    return inputs\n\n# Apply the preprocessing\ntrain_dataset = train_data.apply(preprocess_function, axis=1)\nval_dataset = validation_data.apply(preprocess_function, axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T05:30:40.492253Z","iopub.execute_input":"2024-12-19T05:30:40.492544Z","iopub.status.idle":"2024-12-19T05:30:44.498544Z","shell.execute_reply.started":"2024-12-19T05:30:40.492507Z","shell.execute_reply":"2024-12-19T05:30:44.497838Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"train_dataset[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T05:30:44.499552Z","iopub.execute_input":"2024-12-19T05:30:44.499893Z","iopub.status.idle":"2024-12-19T05:30:44.506381Z","shell.execute_reply.started":"2024-12-19T05:30:44.499856Z","shell.execute_reply":"2024-12-19T05:30:44.505320Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [25208, 10, 7102, 55, 3, 23, 764, 640, 48, 403, 17, 77, 31, 7, 1108, 11, 3, 23, 816, 24, 25, 429, 253, 34, 1477, 25208, 10, 3, 7997, 15, 10, 7102, 55, 3, 10, 61, 2049, 6, 68, 3, 23, 31, 162, 641, 608, 34, 5, 3, 10, 61, 3, 7997, 15, 10, 68, 2049, 21, 1631, 81, 140, 3, 10, 61, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [25208, 1622, 3, 7997, 15, 403, 17, 77, 31, 7, 1108, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}"},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":"# Fine Tuning Model","metadata":{}},{"cell_type":"code","source":"model = T5ForConditionalGeneration.from_pretrained('t5-small')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T05:30:44.507742Z","iopub.execute_input":"2024-12-19T05:30:44.508361Z","iopub.status.idle":"2024-12-19T05:30:47.205485Z","shell.execute_reply.started":"2024-12-19T05:30:44.508332Z","shell.execute_reply":"2024-12-19T05:30:47.204654Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77490525b51b439da8f94a0eceb948c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57f5ef866de84fc6bcab4bd0a49828d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7fca374cf7ac4e73b28150496dfd9d83"}},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"# Define training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",          # output directory for checkpoinnts\n    num_train_epochs=6,              # number of training epochs\n    per_device_train_batch_size=8,   # batch size per device during training\n    per_device_eval_batch_size=8,    # batch size for evaluation\n    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n    weight_decay=0.01,               # strength of weight decay\n    logging_dir=\"./logs\",            # directory for storing logs\n    logging_steps=50,                # how often to log training info\n    save_steps=500,                  # how often to save a model checkpoint\n    eval_steps=50,                   # how often to run evaluation\n    eval_strategy=\"epoch\",           # ensure evaluation happens every 'epoch'\n)\n\n# Trainer setup\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset\n)\n\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T05:30:47.207082Z","iopub.execute_input":"2024-12-19T05:30:47.207447Z","iopub.status.idle":"2024-12-19T05:45:05.676089Z","shell.execute_reply.started":"2024-12-19T05:30:47.207408Z","shell.execute_reply":"2024-12-19T05:45:05.675039Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.7"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241219_053326-4o7it2v2</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/vardhan-ayush03-motilal-nehru-national-institute-of-tech/huggingface/runs/4o7it2v2' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/vardhan-ayush03-motilal-nehru-national-institute-of-tech/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/vardhan-ayush03-motilal-nehru-national-institute-of-tech/huggingface' target=\"_blank\">https://wandb.ai/vardhan-ayush03-motilal-nehru-national-institute-of-tech/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/vardhan-ayush03-motilal-nehru-national-institute-of-tech/huggingface/runs/4o7it2v2' target=\"_blank\">https://wandb.ai/vardhan-ayush03-motilal-nehru-national-institute-of-tech/huggingface/runs/4o7it2v2</a>"},"metadata":{}},{"name":"stderr","text":"Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3000/3000 11:35, Epoch 6/6]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.424600</td>\n      <td>0.373314</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.378400</td>\n      <td>0.355375</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.371100</td>\n      <td>0.351307</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.363100</td>\n      <td>0.346070</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.350000</td>\n      <td>0.344877</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.353400</td>\n      <td>0.345019</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=3000, training_loss=0.9062748317718505, metrics={'train_runtime': 856.4752, 'train_samples_per_second': 28.022, 'train_steps_per_second': 3.503, 'total_flos': 3248203235328000.0, 'train_loss': 0.9062748317718505, 'epoch': 6.0})"},"metadata":{}}],"execution_count":14},{"cell_type":"markdown","source":"# Save and Load model","metadata":{}},{"cell_type":"code","source":"model.save_pretrained('./saved_summary_model')\ntokenizer.save_pretrained('./saved_summary_model')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T05:45:05.678571Z","iopub.execute_input":"2024-12-19T05:45:05.678845Z","iopub.status.idle":"2024-12-19T05:45:06.222960Z","shell.execute_reply.started":"2024-12-19T05:45:05.678818Z","shell.execute_reply":"2024-12-19T05:45:06.222109Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"('./saved_summary_model/tokenizer_config.json',\n './saved_summary_model/special_tokens_map.json',\n './saved_summary_model/spiece.model',\n './saved_summary_model/added_tokens.json')"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"# Load the saved model and tokenizer\nmodel = T5ForConditionalGeneration.from_pretrained(\"./saved_summary_model\")\ntokenizer = T5Tokenizer.from_pretrained(\"./saved_summary_model\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T05:45:06.223964Z","iopub.execute_input":"2024-12-19T05:45:06.224221Z","iopub.status.idle":"2024-12-19T05:45:06.668691Z","shell.execute_reply.started":"2024-12-19T05:45:06.224195Z","shell.execute_reply":"2024-12-19T05:45:06.668019Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"# Summarization System","metadata":{}},{"cell_type":"code","source":"device = model.device # GPU, CPU\n\ndef summarize_dialogue(dialogue):\n    dialogue = clean_text(dialogue)\n    inputs = tokenizer(dialogue, return_tensors='pt', truncation=True, padding='max_length', max_length=512)\n\n    inputs = {key: value.to(device) for key, values in inputs.items()}\n\n    outputs = model.generate(\n        inputs['input_ids'],\n        max_length = 150,\n        num_beams = 4,\n        early_stopping = True\n    )\n\n    summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    return summary","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T05:45:06.669727Z","iopub.execute_input":"2024-12-19T05:45:06.669994Z","iopub.status.idle":"2024-12-19T05:45:06.676053Z","shell.execute_reply.started":"2024-12-19T05:45:06.669968Z","shell.execute_reply":"2024-12-19T05:45:06.675290Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"# Download Mode to your Machine","metadata":{}},{"cell_type":"code","source":"import shutil\n\n# Path to the directory containing the fine-tuned model\nmodel_dir = \"./saved_summary_model\"\n\n# Output zip file path\noutput_zip_path = \"saved_summary_model.zip\"\n\n# Create a zip archive\nshutil.make_archive(base_name=\"saved_summary_model\", format=\"zip\", root_dir=model_dir)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T05:45:06.676948Z","iopub.execute_input":"2024-12-19T05:45:06.677183Z","iopub.status.idle":"2024-12-19T05:45:19.821210Z","shell.execute_reply.started":"2024-12-19T05:45:06.677158Z","shell.execute_reply":"2024-12-19T05:45:19.820336Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/saved_summary_model.zip'"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"from IPython.display import FileLink\n\n# Display a download link\nFileLink(output_zip_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T05:45:19.822424Z","iopub.execute_input":"2024-12-19T05:45:19.822792Z","iopub.status.idle":"2024-12-19T05:45:19.829295Z","shell.execute_reply.started":"2024-12-19T05:45:19.822753Z","shell.execute_reply":"2024-12-19T05:45:19.828413Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/saved_summary_model.zip","text/html":"<a href='saved_summary_model.zip' target='_blank'>saved_summary_model.zip</a><br>"},"metadata":{}}],"execution_count":19}]}